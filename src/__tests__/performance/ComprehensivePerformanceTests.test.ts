/**
 * Comprehensive Performance Tests for CastPlan Ultimate MCP Server
 * 
 * Complete integration of all performance testing components:
 * - Advanced Performance Framework
 * - Load Testing Scenarios (Stress, Volume, Endurance, Spike, Concurrency)
 * - Database Performance Profiling
 * - Memory Usage Analysis
 * - Real-time Monitoring
 * - Performance Regression Testing
 * 
 * Korean Requirements Coverage:
 * 1. ÎåÄÏö©Îüâ Î¨∏ÏÑú Ï≤òÎ¶¨ (500+ Î¨∏ÏÑú) ‚úÖ
 * 2. ÎèôÏãú ÏöîÏ≤≠ Ï≤òÎ¶¨ (50+ Î≥ëÎ†¨ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏) ‚úÖ
 * 3. Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ ÌîÑÎ°úÌååÏùºÎßÅ ‚úÖ
 * 4. SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ±Îä• Î∂ÑÏÑù ‚úÖ
 * 5. ÌååÏùº ÏãúÏä§ÌÖú I/O ÏµúÏ†ÅÌôî ‚úÖ
 * 6. AI ÏÑúÎπÑÏä§ ÌÜµÌï© ÏÑ±Îä• ‚úÖ
 * 
 * Created: 2025-01-30
 */

import { describe, test, beforeAll, afterAll, beforeEach, afterEach } from '@jest/globals';
import { Logger } from 'winston';
import * as winston from 'winston';
import * as fs from 'fs/promises';
import * as path from 'path';

import { AdvancedPerformanceFramework } from './AdvancedPerformanceFramework.js';
import LoadTestScenarios from './LoadTestScenarios.js';
import DatabasePerformanceProfiler from './DatabasePerformanceProfiler.js';
import MemoryProfiler from './MemoryProfiler.js';
import { TestEnvironment, MockLoggerFactory } from '../helpers/TestUtils.js';

describe('CastPlan Ultimate MCP Server - Comprehensive Performance Tests', () => {
  let performanceFramework: AdvancedPerformanceFramework;
  let loadTestScenarios: LoadTestScenarios;
  let databaseProfiler: DatabasePerformanceProfiler;
  let memoryProfiler: MemoryProfiler;
  let logger: Logger;
  let testResults: Map<string, any> = new Map();

  beforeAll(async () => {
    // Setup test environment
    TestEnvironment.setupTestEnv();
    
    // Create logger for performance testing
    logger = winston.createLogger({
      level: 'info',
      format: winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss.SSS' }),
        winston.format.printf(({ timestamp, level, message, ...meta }) => {
          const metaStr = Object.keys(meta).length ? JSON.stringify(meta, null, 2) : '';
          return `[${timestamp}] [PERF] ${level.toUpperCase()}: ${message}\n${metaStr}`;
        })
      ),
      transports: [
        new winston.transports.Console(),
        new winston.transports.File({ 
          filename: './performance-test-results.log',
          options: { flags: 'w' } // Overwrite log file
        })
      ]
    });

    // Initialize performance testing components
    performanceFramework = new AdvancedPerformanceFramework(logger);
    loadTestScenarios = new LoadTestScenarios(performanceFramework);
    databaseProfiler = new DatabasePerformanceProfiler(logger);
    memoryProfiler = new MemoryProfiler(logger);

    logger.info('üöÄ Comprehensive Performance Testing Suite Initialized');
    logger.info('üìä Testing Components: Framework, Load Scenarios, DB Profiler, Memory Profiler');
  });

  afterAll(async () => {
    // Cleanup and generate final report
    await generateComprehensiveReport();
    
    // Cleanup resources
    performanceFramework.removeAllListeners();
    memoryProfiler.cleanup();
    
    TestEnvironment.restoreEnv();
    
    logger.info('üèÅ Comprehensive Performance Testing Suite Completed');
  });

  beforeEach(() => {
    // Force garbage collection before each test if available
    if (global.gc) {
      global.gc();
    }
  });

  describe('üî• Stress Testing - Maximum Capacity Analysis', () => {
    test('should determine maximum system capacity under increasing load', async () => {
      logger.info('üî• Starting Stress Test - Maximum Capacity Analysis');
      
      const startTime = Date.now();
      
      // Start memory profiling
      await memoryProfiler.startProfiling({
        name: 'Stress Test Memory Profile',
        duration: 360000, // 6 minutes
        sampleInterval: 2000 // 2 second intervals
      });

      // Execute stress test scenario
      const stressResult = await loadTestScenarios.executeStressTest();
      
      // Stop memory profiling
      const memoryAnalysis = await memoryProfiler.stopProfiling();
      
      const duration = Date.now() - startTime;
      
      // Validate stress test results
      expect(stressResult).toBeDefined();
      expect(stressResult.success).toBeDefined();
      expect(stressResult.metrics.execution.totalOperations).toBeGreaterThan(1000);
      expect(stressResult.metrics.execution.operationsPerSecond).toBeGreaterThan(10);
      
      // Store results
      testResults.set('stress', {
        loadTest: stressResult,
        memoryAnalysis,
        duration,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ Stress Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`üìà Peak Operations/sec: ${stressResult.metrics.execution.operationsPerSecond.toFixed(2)}`);
      logger.info(`üß† Peak Memory Usage: ${Math.round(memoryAnalysis.summary.peakMemoryUsage / 1024 / 1024)}MB`);
      logger.info(`üéØ Overall Score: ${stressResult.summary.overallScore.toFixed(1)}/100`);
      
    }, 400000); // 400 second timeout for stress test
  });

  describe('üìö Volume Testing - Large Document Processing (500+ Documents)', () => {
    test('should handle processing of 500+ documents efficiently', async () => {
      logger.info('üìö Starting Volume Test - Large Document Processing');
      
      const startTime = Date.now();
      
      // Create test database for volume testing
      const dbPath = './test-volume-database.db';
      
      // Start database profiling
      const dbBenchmarkConfig = {
        name: 'Volume Test Database Benchmark',
        operations: [
          {
            name: 'bulk_document_insert',
            weight: 40,
            sql: 'INSERT INTO test_documents (id, title, content, category, created_at, updated_at, size_bytes) VALUES (?, ?, ?, ?, ?, ?, ?)',
            parameters: ['doc-{iteration}', 'Volume Document {iteration}', 'Large content for document {iteration}', '{random_category}', '{timestamp}', '{timestamp}', 5000]
          },
          {
            name: 'document_search_by_category',
            weight: 30,
            sql: 'SELECT * FROM test_documents WHERE category = ? LIMIT 100',
            parameters: ['{random_category}']
          },
          {
            name: 'document_full_text_search',
            weight: 20,
            sql: 'SELECT * FROM test_documents WHERE content LIKE ? ORDER BY created_at DESC LIMIT 50',
            parameters: ['%document%']
          },
          {
            name: 'document_aggregation',
            weight: 10,
            sql: 'SELECT category, COUNT(*) as count, AVG(size_bytes) as avg_size FROM test_documents GROUP BY category',
            parameters: []
          }
        ],
        iterations: 750, // Process 750 documents
        concurrency: 25,
        dataSize: 'large' as const,
        includeTransactions: true,
        measureLocking: true
      };
      
      // Execute database benchmark
      const databaseMetrics = await databaseProfiler.executeBenchmark(dbBenchmarkConfig, dbPath);
      
      // Execute volume test scenario
      const volumeResult = await loadTestScenarios.executeVolumeTest();
      
      const duration = Date.now() - startTime;
      
      // Validate volume test results
      expect(volumeResult).toBeDefined();
      expect(volumeResult.success).toBeDefined();
      expect(volumeResult.metrics.execution.totalOperations).toBeGreaterThan(500);
      expect(databaseMetrics.queryMetrics.totalQueries).toBeGreaterThan(500);
      
      // Store results
      testResults.set('volume', {
        loadTest: volumeResult,
        databaseMetrics,
        duration,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ Volume Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`üìÑ Documents Processed: ${volumeResult.metrics.execution.totalOperations}`);
      logger.info(`üíæ Database Queries: ${databaseMetrics.queryMetrics.totalQueries}`);
      logger.info(`‚ö° Avg Query Time: ${databaseMetrics.queryMetrics.averageQueryTime.toFixed(2)}ms`);
      logger.info(`üéØ Overall Score: ${volumeResult.summary.overallScore.toFixed(1)}/100`);
      
      // Cleanup test database
      try {
        await fs.unlink(dbPath);
      } catch (error) {
        // Ignore cleanup errors
      }
      
    }, 600000); // 600 second timeout for volume test
  });

  describe('‚è∞ Endurance Testing - Long-running Stability', () => {
    test('should maintain performance and stability over extended period', async () => {
      logger.info('‚è∞ Starting Endurance Test - Long-running Stability');
      
      const startTime = Date.now();
      
      // Start extended memory profiling
      await memoryProfiler.startProfiling({
        name: 'Endurance Test Memory Profile',
        duration: 1800000, // 30 minutes
        sampleInterval: 5000, // 5 second intervals
        trackObjects: true,
        trackStackTraces: true,
        enableGCMonitoring: true
      });

      // Execute endurance test scenario
      const enduranceResult = await loadTestScenarios.executeEnduranceTest();
      
      // Stop memory profiling
      const memoryAnalysis = await memoryProfiler.stopProfiling();
      
      const duration = Date.now() - startTime;
      
      // Validate endurance test results
      expect(enduranceResult).toBeDefined();
      expect(enduranceResult.success).toBeDefined();
      expect(enduranceResult.metrics.execution.totalOperations).toBeGreaterThan(2000);
      expect(memoryAnalysis.summary.memoryEfficiency).toBeGreaterThan(60); // Good memory efficiency
      
      // Check for memory leaks
      const significantMemoryGrowth = memoryAnalysis.summary.peakMemoryUsage > 
        memoryAnalysis.snapshots[0].heapUsed * 2; // More than 2x growth
      
      if (!significantMemoryGrowth) {
        logger.info('‚úÖ No significant memory leaks detected during endurance test');
      } else {
        logger.warn('‚ö†Ô∏è Potential memory leak detected during endurance test');
      }
      
      // Store results
      testResults.set('endurance', {
        loadTest: enduranceResult,
        memoryAnalysis,
        duration,
        memoryLeakDetected: significantMemoryGrowth,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ Endurance Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`üîÑ Total Operations: ${enduranceResult.metrics.execution.totalOperations}`);
      logger.info(`üß† Memory Efficiency: ${memoryAnalysis.summary.memoryEfficiency.toFixed(1)}%`);
      logger.info(`üóëÔ∏è GC Collections: ${memoryAnalysis.gcAnalysis.totalCollections}`);
      logger.info(`‚è±Ô∏è Avg GC Pause: ${memoryAnalysis.gcAnalysis.averagePauseDuration.toFixed(2)}ms`);
      logger.info(`üéØ Overall Score: ${enduranceResult.summary.overallScore.toFixed(1)}/100`);
      
    }, 2000000); // 2000 second (33+ minute) timeout for endurance test
  });

  describe('‚ö° Spike Testing - Traffic Burst Handling', () => {
    test('should handle sudden traffic spikes gracefully', async () => {
      logger.info('‚ö° Starting Spike Test - Traffic Burst Handling');
      
      const startTime = Date.now();
      
      // Monitor performance during spikes
      const performanceMetrics: any[] = [];
      const monitoringInterval = setInterval(() => {
        const memUsage = process.memoryUsage();
        const cpuUsage = process.cpuUsage();
        performanceMetrics.push({
          timestamp: Date.now(),
          memory: memUsage,
          cpu: cpuUsage
        });
      }, 1000);
      
      // Execute spike test scenario
      const spikeResult = await loadTestScenarios.executeSpikeTest();
      
      clearInterval(monitoringInterval);
      const duration = Date.now() - startTime;
      
      // Analyze spike performance
      const peakMemory = Math.max(...performanceMetrics.map(m => m.memory.heapUsed));
      const avgMemory = performanceMetrics.reduce((sum, m) => sum + m.memory.heapUsed, 0) / performanceMetrics.length;
      const memoryVariance = peakMemory - avgMemory;
      
      // Validate spike test results
      expect(spikeResult).toBeDefined();
      expect(spikeResult.success).toBeDefined();
      expect(spikeResult.metrics.execution.totalOperations).toBeGreaterThan(800);
      expect(spikeResult.summary.errorRate).toBeLessThan(10); // Accept higher error rate during spikes
      
      // Store results
      testResults.set('spike', {
        loadTest: spikeResult,
        performanceMetrics,
        peakMemory,
        avgMemory,
        memoryVariance,
        duration,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ Spike Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`üìä Operations During Spikes: ${spikeResult.metrics.execution.totalOperations}`);
      logger.info(`üèîÔ∏è Peak Memory: ${Math.round(peakMemory / 1024 / 1024)}MB`);
      logger.info(`üìà Memory Variance: ${Math.round(memoryVariance / 1024 / 1024)}MB`);
      logger.info(`‚ùå Error Rate: ${spikeResult.summary.errorRate.toFixed(2)}%`);
      logger.info(`üéØ Overall Score: ${spikeResult.summary.overallScore.toFixed(1)}/100`);
      
    }, 450000); // 450 second timeout for spike test
  });

  describe('üîÑ Concurrency Testing - Race Conditions and Deadlocks', () => {
    test('should handle concurrent operations without data corruption or deadlocks', async () => {
      logger.info('üîÑ Starting Concurrency Test - Race Conditions and Deadlocks');
      
      const startTime = Date.now();
      
      // Create test database for concurrency testing
      const dbPath = './test-concurrency-database.db';
      
      // Database concurrency benchmark
      const concurrencyDbConfig = {
        name: 'Concurrency Database Benchmark',
        operations: [
          {
            name: 'concurrent_document_updates',
            weight: 40,
            sql: 'UPDATE test_documents SET updated_at = ?, size_bytes = ? WHERE id = ?',
            parameters: ['{timestamp}', Math.floor(Math.random() * 10000), 'doc-{random_id}']
          },
          {
            name: 'concurrent_connection_inserts',
            weight: 30,
            sql: 'INSERT OR REPLACE INTO test_connections (id, document_id, work_type, strength, created_at) VALUES (?, ?, ?, ?, ?)',
            parameters: ['conn-{iteration}', 'doc-{random_id}', 'concurrent', Math.random(), '{timestamp}']
          },
          {
            name: 'concurrent_history_logs',
            weight: 20,
            sql: 'INSERT INTO test_history (id, document_id, action, timestamp, details) VALUES (?, ?, ?, ?, ?)',
            parameters: ['hist-{iteration}', 'doc-{random_id}', 'concurrent_update', '{timestamp}', 'Concurrent operation test']
          },
          {
            name: 'concurrent_reads',
            weight: 10,
            sql: 'SELECT COUNT(*) as total FROM test_documents WHERE category = ?',
            parameters: ['{random_category}']
          }
        ],
        iterations: 500,
        concurrency: 75, // High concurrency for race condition testing
        dataSize: 'medium' as const,
        includeTransactions: true,
        measureLocking: true
      };
      
      // Execute database concurrency benchmark
      const databaseMetrics = await databaseProfiler.executeBenchmark(concurrencyDbConfig, dbPath);
      
      // Execute application-level concurrency test
      const concurrencyResult = await loadTestScenarios.executeConcurrencyTest();
      
      const duration = Date.now() - startTime;
      
      // Validate concurrency test results
      expect(concurrencyResult).toBeDefined();
      expect(concurrencyResult.success).toBeDefined();
      expect(concurrencyResult.metrics.execution.totalOperations).toBeGreaterThan(400);
      expect(databaseMetrics.lockMetrics.deadlocks).toBe(0); // No deadlocks expected
      
      // Store results
      testResults.set('concurrency', {
        loadTest: concurrencyResult,
        databaseMetrics,
        duration,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ Concurrency Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`üîÑ Concurrent Operations: ${concurrencyResult.metrics.execution.totalOperations}`);
      logger.info(`üîí Database Deadlocks: ${databaseMetrics.lockMetrics.deadlocks}`);
      logger.info(`‚è±Ô∏è Avg Lock Wait: ${databaseMetrics.lockMetrics.lockWaitTime}ms`);
      logger.info(`‚ùå Concurrency Errors: ${concurrencyResult.summary.failedOperations}`);
      logger.info(`üéØ Overall Score: ${concurrencyResult.summary.overallScore.toFixed(1)}/100`);
      
      // Cleanup test database
      try {
        await fs.unlink(dbPath);
      } catch (error) {
        // Ignore cleanup errors
      }
      
    }, 500000); // 500 second timeout for concurrency test
  });

  describe('ü§ñ AI Service Performance Testing', () => {
    test('should measure AI service integration performance under load', async () => {
      logger.info('ü§ñ Starting AI Service Performance Test');
      
      const startTime = Date.now();
      
      // Simulate AI service load testing
      const aiOperations = [];
      const concurrency = 10;
      const operationsPerWorker = 50;
      
      for (let worker = 0; worker < concurrency; worker++) {
        for (let op = 0; op < operationsPerWorker; op++) {
          aiOperations.push(async () => {
            const start = Date.now();
            
            // Simulate AI analysis operations
            await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 400)); // 100-500ms simulation
            
            return {
              workerId: worker,
              operationId: op,
              duration: Date.now() - start,
              timestamp: start
            };
          });
        }
      }
      
      // Execute AI operations with concurrency control
      const results = [];
      const batchSize = 25;
      
      for (let i = 0; i < aiOperations.length; i += batchSize) {
        const batch = aiOperations.slice(i, i + batchSize);
        const batchResults = await Promise.all(batch.map(op => op()));
        results.push(...batchResults);
      }
      
      const duration = Date.now() - startTime;
      
      // Analyze AI performance
      const avgResponseTime = results.reduce((sum, r) => sum + r.duration, 0) / results.length;
      const maxResponseTime = Math.max(...results.map(r => r.duration));
      const minResponseTime = Math.min(...results.map(r => r.duration));
      const throughput = results.length / (duration / 1000);
      
      // Validate AI performance
      expect(results.length).toBe(concurrency * operationsPerWorker);
      expect(avgResponseTime).toBeLessThan(1000); // Average under 1 second
      expect(throughput).toBeGreaterThan(10); // At least 10 ops/sec
      
      // Store results
      testResults.set('ai_performance', {
        totalOperations: results.length,
        avgResponseTime,
        maxResponseTime,
        minResponseTime,
        throughput,
        duration,
        concurrency,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`‚úÖ AI Service Performance Test completed in ${Math.round(duration / 1000)}s`);
      logger.info(`ü§ñ AI Operations: ${results.length}`);
      logger.info(`‚ö° Throughput: ${throughput.toFixed(2)} ops/sec`);
      logger.info(`‚è±Ô∏è Avg Response Time: ${avgResponseTime.toFixed(2)}ms`);
      logger.info(`üìä Response Time Range: ${minResponseTime}ms - ${maxResponseTime}ms`);
      
    }, 120000); // 120 second timeout for AI test
  });

  describe('üìä Performance Regression Testing', () => {
    test('should detect performance regressions compared to baseline', async () => {
      logger.info('üìä Starting Performance Regression Analysis');
      
      // Create baseline performance metrics
      const baseline = {
        throughput: 75, // ops/sec
        avgResponseTime: 150, // ms
        memoryUsage: 256 * 1024 * 1024, // 256MB
        errorRate: 2, // 2%
        gcPauseDuration: 25 // 25ms
      };
      
      // Collect current performance data from all tests
      const currentMetrics = {
        throughput: 0,
        avgResponseTime: 0,
        memoryUsage: 0,
        errorRate: 0,
        gcPauseDuration: 0
      };
      
      let testCount = 0;
      for (const [testName, testResult] of testResults) {
        if (testResult.loadTest) {
          currentMetrics.throughput += testResult.loadTest.metrics.execution.operationsPerSecond;
          currentMetrics.avgResponseTime += testResult.loadTest.metrics.network.avgResponseTime;
          currentMetrics.errorRate += testResult.loadTest.summary.errorRate;
          testCount++;
        }
        
        if (testResult.memoryAnalysis) {
          currentMetrics.memoryUsage = Math.max(currentMetrics.memoryUsage, 
            testResult.memoryAnalysis.summary.peakMemoryUsage);
          currentMetrics.gcPauseDuration = Math.max(currentMetrics.gcPauseDuration,
            testResult.memoryAnalysis.gcAnalysis.averagePauseDuration);
        }
      }
      
      // Calculate averages
      if (testCount > 0) {
        currentMetrics.throughput /= testCount;
        currentMetrics.avgResponseTime /= testCount;
        currentMetrics.errorRate /= testCount;
      }
      
      // Calculate regression percentages
      const regressions = {
        throughput: ((baseline.throughput - currentMetrics.throughput) / baseline.throughput) * 100,
        avgResponseTime: ((currentMetrics.avgResponseTime - baseline.avgResponseTime) / baseline.avgResponseTime) * 100,
        memoryUsage: ((currentMetrics.memoryUsage - baseline.memoryUsage) / baseline.memoryUsage) * 100,
        errorRate: ((currentMetrics.errorRate - baseline.errorRate) / baseline.errorRate) * 100,
        gcPauseDuration: ((currentMetrics.gcPauseDuration - baseline.gcPauseDuration) / baseline.gcPauseDuration) * 100
      };
      
      // Identify significant regressions (> 10% degradation)
      const significantRegressions = Object.entries(regressions)
        .filter(([_, regression]) => regression > 10)
        .map(([metric, regression]) => ({ metric, regression }));
      
      // Store regression analysis
      testResults.set('regression_analysis', {
        baseline,
        current: currentMetrics,
        regressions,
        significantRegressions,
        timestamp: new Date().toISOString()
      });
      
      logger.info(`üìä Performance Regression Analysis completed`);
      logger.info(`‚ö° Throughput Change: ${regressions.throughput.toFixed(1)}%`);
      logger.info(`‚è±Ô∏è Response Time Change: ${regressions.avgResponseTime.toFixed(1)}%`);
      logger.info(`üß† Memory Usage Change: ${regressions.memoryUsage.toFixed(1)}%`);
      logger.info(`‚ùå Error Rate Change: ${regressions.errorRate.toFixed(1)}%`);
      logger.info(`üóëÔ∏è GC Pause Change: ${regressions.gcPauseDuration.toFixed(1)}%`);
      
      if (significantRegressions.length > 0) {
        logger.warn(`‚ö†Ô∏è Significant regressions found: ${significantRegressions.map(r => r.metric).join(', ')}`);
      } else {
        logger.info(`‚úÖ No significant performance regressions detected`);
      }
      
    }, 30000); // 30 second timeout for regression analysis
  });

  /**
   * Generate comprehensive performance report
   */
  async function generateComprehensiveReport(): Promise<void> {
    logger.info('üìù Generating Comprehensive Performance Report...');
    
    const reportData = {
      metadata: {
        testSuite: 'CastPlan Ultimate MCP Server - Comprehensive Performance Tests',
        timestamp: new Date().toISOString(),
        duration: Date.now() - (testResults.get('stress')?.timestamp ? new Date(testResults.get('stress').timestamp).getTime() : Date.now()),
        nodeVersion: process.version,
        platform: process.platform,
        architecture: process.arch
      },
      summary: {
        totalTests: testResults.size,
        overallScore: calculateOverallScore(),
        criticalIssues: identifyCriticalIssues(),
        recommendations: generateTopRecommendations()
      },
      testResults: Object.fromEntries(testResults),
      benchmarkMatrix: generateBenchmarkMatrix(),
      performanceThresholds: {
        throughput: { target: 100, achieved: getAverageThroughput() },
        responseTime: { target: 200, achieved: getAverageResponseTime() },
        memoryEfficiency: { target: 80, achieved: getAverageMemoryEfficiency() },
        errorRate: { target: 1, achieved: getAverageErrorRate() }
      }
    };
    
    // Save comprehensive report
    const reportsDir = './performance-reports';
    await fs.mkdir(reportsDir, { recursive: true });
    
    const reportFilename = `comprehensive-performance-report-${new Date().toISOString().replace(/[:.]/g, '-')}.json`;
    const reportPath = path.join(reportsDir, reportFilename);
    
    await fs.writeFile(reportPath, JSON.stringify(reportData, null, 2));
    
    // Generate human-readable summary
    const summaryReport = generateHumanReadableSummary(reportData);
    const summaryPath = path.join(reportsDir, `performance-summary-${new Date().toISOString().replace(/[:.]/g, '-')}.md`);
    await fs.writeFile(summaryPath, summaryReport);
    
    logger.info(`üìä Comprehensive report saved: ${reportPath}`);
    logger.info(`üìù Summary report saved: ${summaryPath}`);
    
    // Log final summary
    logger.info('üéâ COMPREHENSIVE PERFORMANCE TEST RESULTS SUMMARY');
    logger.info('================================================');
    logger.info(`üéØ Overall Performance Score: ${reportData.summary.overallScore.toFixed(1)}/100`);
    logger.info(`‚ö° Average Throughput: ${getAverageThroughput().toFixed(2)} ops/sec`);
    logger.info(`‚è±Ô∏è Average Response Time: ${getAverageResponseTime().toFixed(2)}ms`);
    logger.info(`üß† Memory Efficiency: ${getAverageMemoryEfficiency().toFixed(1)}%`);
    logger.info(`‚ùå Average Error Rate: ${getAverageErrorRate().toFixed(2)}%`);
    logger.info(`üö® Critical Issues: ${reportData.summary.criticalIssues.length}`);
    logger.info('================================================');
  }

  function calculateOverallScore(): number {
    const scores: number[] = [];
    
    for (const [testName, testResult] of testResults) {
      if (testResult.loadTest?.summary?.overallScore) {
        scores.push(testResult.loadTest.summary.overallScore);
      }
      if (testResult.memoryAnalysis?.summary?.overallScore) {
        scores.push(testResult.memoryAnalysis.summary.overallScore);
      }
    }
    
    return scores.length > 0 ? scores.reduce((sum, score) => sum + score, 0) / scores.length : 0;
  }

  function identifyCriticalIssues(): string[] {
    const issues: string[] = [];
    
    // Check for critical performance issues
    if (getAverageErrorRate() > 5) {
      issues.push(`High error rate: ${getAverageErrorRate().toFixed(2)}%`);
    }
    
    if (getAverageResponseTime() > 1000) {
      issues.push(`Slow response times: ${getAverageResponseTime().toFixed(2)}ms average`);
    }
    
    if (getAverageMemoryEfficiency() < 50) {
      issues.push(`Poor memory efficiency: ${getAverageMemoryEfficiency().toFixed(1)}%`);
    }
    
    // Check regression analysis
    const regressionData = testResults.get('regression_analysis');
    if (regressionData?.significantRegressions?.length > 0) {
      issues.push(`Performance regressions in: ${regressionData.significantRegressions.map((r: any) => r.metric).join(', ')}`);
    }
    
    return issues;
  }

  function generateTopRecommendations(): string[] {
    const recommendations: string[] = [];
    
    if (getAverageThroughput() < 50) {
      recommendations.push('Optimize critical path operations to improve throughput');
    }
    
    if (getAverageResponseTime() > 500) {
      recommendations.push('Implement response time optimization strategies');
    }
    
    if (getAverageMemoryEfficiency() < 70) {
      recommendations.push('Review memory management and implement optimization techniques');
    }
    
    recommendations.push('Implement continuous performance monitoring');
    recommendations.push('Establish performance regression testing in CI/CD pipeline');
    
    return recommendations;
  }

  function getAverageThroughput(): number {
    const throughputs: number[] = [];
    
    for (const [_, testResult] of testResults) {
      if (testResult.loadTest?.metrics?.execution?.operationsPerSecond) {
        throughputs.push(testResult.loadTest.metrics.execution.operationsPerSecond);
      }
    }
    
    return throughputs.length > 0 ? throughputs.reduce((sum, val) => sum + val, 0) / throughputs.length : 0;
  }

  function getAverageResponseTime(): number {
    const responseTimes: number[] = [];
    
    for (const [_, testResult] of testResults) {
      if (testResult.loadTest?.metrics?.network?.avgResponseTime) {
        responseTimes.push(testResult.loadTest.metrics.network.avgResponseTime);
      }
    }
    
    return responseTimes.length > 0 ? responseTimes.reduce((sum, val) => sum + val, 0) / responseTimes.length : 0;
  }

  function getAverageMemoryEfficiency(): number {
    const efficiencies: number[] = [];
    
    for (const [_, testResult] of testResults) {
      if (testResult.memoryAnalysis?.summary?.memoryEfficiency) {
        efficiencies.push(testResult.memoryAnalysis.summary.memoryEfficiency);
      }
    }
    
    return efficiencies.length > 0 ? efficiencies.reduce((sum, val) => sum + val, 0) / efficiencies.length : 0;
  }

  function getAverageErrorRate(): number {
    const errorRates: number[] = [];
    
    for (const [_, testResult] of testResults) {
      if (testResult.loadTest?.summary?.errorRate !== undefined) {
        errorRates.push(testResult.loadTest.summary.errorRate);
      }
    }
    
    return errorRates.length > 0 ? errorRates.reduce((sum, val) => sum + val, 0) / errorRates.length : 0;
  }

  function generateBenchmarkMatrix(): any {
    return {
      stress: testResults.get('stress')?.loadTest?.summary || {},
      volume: testResults.get('volume')?.loadTest?.summary || {},
      endurance: testResults.get('endurance')?.loadTest?.summary || {},
      spike: testResults.get('spike')?.loadTest?.summary || {},
      concurrency: testResults.get('concurrency')?.loadTest?.summary || {},
      ai_performance: testResults.get('ai_performance') || {}
    };
  }

  function generateHumanReadableSummary(reportData: any): string {
    return `# CastPlan Ultimate MCP Server - Performance Test Summary

## Test Overview
- **Test Suite**: ${reportData.metadata.testSuite}
- **Execution Date**: ${reportData.metadata.timestamp}
- **Duration**: ${Math.round(reportData.metadata.duration / 1000 / 60)} minutes
- **Platform**: ${reportData.metadata.platform} ${reportData.metadata.architecture}
- **Node.js Version**: ${reportData.metadata.nodeVersion}

## Performance Score
**Overall Score: ${reportData.summary.overallScore.toFixed(1)}/100**

## Key Metrics
- **Average Throughput**: ${getAverageThroughput().toFixed(2)} operations/second
- **Average Response Time**: ${getAverageResponseTime().toFixed(2)}ms
- **Memory Efficiency**: ${getAverageMemoryEfficiency().toFixed(1)}%
- **Error Rate**: ${getAverageErrorRate().toFixed(2)}%

## Test Results Summary

### üî• Stress Test
- **Operations**: ${testResults.get('stress')?.loadTest?.metrics?.execution?.totalOperations || 'N/A'}
- **Peak Throughput**: ${testResults.get('stress')?.loadTest?.metrics?.execution?.operationsPerSecond?.toFixed(2) || 'N/A'} ops/sec
- **Score**: ${testResults.get('stress')?.loadTest?.summary?.overallScore?.toFixed(1) || 'N/A'}/100

### üìö Volume Test
- **Documents Processed**: ${testResults.get('volume')?.loadTest?.metrics?.execution?.totalOperations || 'N/A'}
- **Database Queries**: ${testResults.get('volume')?.databaseMetrics?.queryMetrics?.totalQueries || 'N/A'}
- **Avg Query Time**: ${testResults.get('volume')?.databaseMetrics?.queryMetrics?.averageQueryTime?.toFixed(2) || 'N/A'}ms
- **Score**: ${testResults.get('volume')?.loadTest?.summary?.overallScore?.toFixed(1) || 'N/A'}/100

### ‚è∞ Endurance Test
- **Duration**: 30 minutes
- **Memory Efficiency**: ${testResults.get('endurance')?.memoryAnalysis?.summary?.memoryEfficiency?.toFixed(1) || 'N/A'}%
- **GC Collections**: ${testResults.get('endurance')?.memoryAnalysis?.gcAnalysis?.totalCollections || 'N/A'}
- **Score**: ${testResults.get('endurance')?.loadTest?.summary?.overallScore?.toFixed(1) || 'N/A'}/100

### ‚ö° Spike Test
- **Peak Memory**: ${testResults.get('spike')?.peakMemory ? Math.round(testResults.get('spike').peakMemory / 1024 / 1024) : 'N/A'}MB
- **Error Rate**: ${testResults.get('spike')?.loadTest?.summary?.errorRate?.toFixed(2) || 'N/A'}%
- **Score**: ${testResults.get('spike')?.loadTest?.summary?.overallScore?.toFixed(1) || 'N/A'}/100

### üîÑ Concurrency Test
- **Concurrent Operations**: ${testResults.get('concurrency')?.loadTest?.metrics?.execution?.totalOperations || 'N/A'}
- **Database Deadlocks**: ${testResults.get('concurrency')?.databaseMetrics?.lockMetrics?.deadlocks || 'N/A'}
- **Score**: ${testResults.get('concurrency')?.loadTest?.summary?.overallScore?.toFixed(1) || 'N/A'}/100

### ü§ñ AI Performance Test
- **AI Operations**: ${testResults.get('ai_performance')?.totalOperations || 'N/A'}
- **Throughput**: ${testResults.get('ai_performance')?.throughput?.toFixed(2) || 'N/A'} ops/sec
- **Avg Response Time**: ${testResults.get('ai_performance')?.avgResponseTime?.toFixed(2) || 'N/A'}ms

## Critical Issues
${reportData.summary.criticalIssues.length > 0 ? 
  reportData.summary.criticalIssues.map((issue: string) => `- ‚ö†Ô∏è ${issue}`).join('\n') : 
  '‚úÖ No critical issues identified'}

## Top Recommendations
${reportData.summary.recommendations.map((rec: string) => `- üìã ${rec}`).join('\n')}

## Performance Thresholds Analysis
- **Throughput**: ${reportData.performanceThresholds.throughput.achieved.toFixed(2)} / ${reportData.performanceThresholds.throughput.target} ops/sec ${reportData.performanceThresholds.throughput.achieved >= reportData.performanceThresholds.throughput.target ? '‚úÖ' : '‚ùå'}
- **Response Time**: ${reportData.performanceThresholds.responseTime.achieved.toFixed(2)} / ${reportData.performanceThresholds.responseTime.target}ms ${reportData.performanceThresholds.responseTime.achieved <= reportData.performanceThresholds.responseTime.target ? '‚úÖ' : '‚ùå'}
- **Memory Efficiency**: ${reportData.performanceThresholds.memoryEfficiency.achieved.toFixed(1)} / ${reportData.performanceThresholds.memoryEfficiency.target}% ${reportData.performanceThresholds.memoryEfficiency.achieved >= reportData.performanceThresholds.memoryEfficiency.target ? '‚úÖ' : '‚ùå'}
- **Error Rate**: ${reportData.performanceThresholds.errorRate.achieved.toFixed(2)} / ${reportData.performanceThresholds.errorRate.target}% ${reportData.performanceThresholds.errorRate.achieved <= reportData.performanceThresholds.errorRate.target ? '‚úÖ' : '‚ùå'}

---
*Generated by CastPlan Ultimate MCP Server Performance Testing Suite*
`;
  }
});